#!/usr/bin/env bash
# Smart PDF Extraction with Automatic Fallback
# Tries MinerU first (fast, free), falls back to Vision-LLM for failures

set -Eeuo pipefail

PDF_FILE="$1"
OUTPUT_DIR="${2:-literature/pdfs/extractions-smart}"

MINERU_OUTPUT="$OUTPUT_DIR/mineru"
VLM_OUTPUT="$OUTPUT_DIR/vlm"

mkdir -p "$MINERU_OUTPUT" "$VLM_OUTPUT"

PDF_NAME=$(basename "$PDF_FILE" .pdf)

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ðŸ” Smart PDF Extraction: $PDF_NAME"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# Stage 1: Try MinerU (GPU-accelerated, local)
echo ""
echo "ðŸ“Š Stage 1: MinerU extraction (GPU)"
echo "  Model: DocLayout-YOLO + Unimernet + RapidTable"
echo "  Cost: $0 (local GPU)"

conda run -n mineru magic-pdf \
    -p "$PDF_FILE" \
    -o "$MINERU_OUTPUT" \
    -m auto \
    2>&1 | tee "$MINERU_OUTPUT/${PDF_NAME}_log.txt"

MINERU_EXIT=$?

# Check if MinerU succeeded
if [ $MINERU_EXIT -eq 0 ]; then
    EXTRACTED_MD="$MINERU_OUTPUT/$PDF_NAME/auto/${PDF_NAME}.md"

    if [ -f "$EXTRACTED_MD" ]; then
        WORD_COUNT=$(wc -w < "$EXTRACTED_MD")

        # Quality check: extracted markdown should have reasonable content
        if [ "$WORD_COUNT" -gt 100 ]; then
            echo ""
            echo "âœ… MinerU SUCCESS"
            echo "  Words extracted: $WORD_COUNT"
            echo "  Output: $EXTRACTED_MD"
            echo ""
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            exit 0
        else
            echo ""
            echo "âš ï¸  MinerU extraction too short ($WORD_COUNT words)"
            echo "  Falling back to Vision-LLM..."
        fi
    else
        echo ""
        echo "âš ï¸  MinerU output file not found"
        echo "  Falling back to Vision-LLM..."
    fi
else
    echo ""
    echo "âŒ MinerU failed (exit code: $MINERU_EXIT)"
    echo "  Falling back to Vision-LLM..."
fi

# Stage 2: Vision-LLM extraction (Ollama Cloud)
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ðŸ¤– Stage 2: Vision-LLM extraction (Cloud)"
echo "  Model: deepseek-v3.1:671b-cloud"
echo "  Provider: Ollama Cloud API"
echo "  Cost: API credits (pay-per-use)"
echo ""

python tools/scripts/extract-hard-ocr-ollama.py \
    "$PDF_FILE" \
    "$VLM_OUTPUT"

VLM_EXIT=$?

if [ $VLM_EXIT -eq 0 ]; then
    echo ""
    echo "âœ… Vision-LLM SUCCESS"
    echo "  Output: $VLM_OUTPUT/${PDF_NAME}.md"
    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    exit 0
else
    echo ""
    echo "âŒ Vision-LLM also failed"
    echo "  Manual intervention required"
    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    exit 1
fi
